import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,
    mean_squared_error, mean_absolute_error, r2_score, confusion_matrix, classification_report
)
# åˆ†ç±»æ¨¡å‹
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
# å›å½’æ¨¡å‹
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor


def rerun():
    """å…¼å®¹ä¸åŒStreamlitç‰ˆæœ¬çš„åˆ·æ–°æ–¹æ³•"""
    if hasattr(st, "experimental_rerun"):
        st.experimental_rerun()
    else:
        st.rerun()


def model_training_page(df):
    """æ¨¡å‹è®­ç»ƒä¸é…ç½®é¡µé¢ï¼ˆæ¥æ”¶dfå‚æ•°ï¼‰"""
    st.header("æ¨¡å‹è®­ç»ƒä¸é…ç½®")

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    init_states = {
        "X_train": None,
        "X_test": None,
        "y_train": None,
        "y_test": None,
        "best_model": None,
        "model_performance": {},
        "test_size": 0.2,
        "random_state": 42,
        "card_style": """
            background-color: #f8f9fa;
            border-radius: 8px;
            padding: 16px;
            margin-bottom: 20px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        """
    }
    for k, v in init_states.items():
        st.session_state.setdefault(k, v)

    # æ£€æŸ¥å¿…è¦çš„ä¼šè¯çŠ¶æ€å˜é‡
    required_states = ["target_col", "features", "task_type"]
    for state in required_states:
        if state not in st.session_state or st.session_state[state] is None:
            st.error(f"âŒ ç¼ºå°‘å¿…è¦çš„é…ç½®ï¼š{state}ï¼Œè¯·è¿”å›ä¸Šä¸€æ­¥å®Œæˆè®¾ç½®")
            if st.button("â† è¿”å›å˜é‡å®šä¹‰é¡µé¢", use_container_width=True):
                st.session_state.current_page = "å˜é‡å®šä¹‰ä¸ä»»åŠ¡è®¾ç½®"
                rerun()
            return

    # æå–ç‰¹å¾å’Œç›®æ ‡å˜é‡
    try:
        X = df[st.session_state.features].copy()
        y = df[st.session_state.target_col].copy()
        st.success(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆï¼š{X.shape[0]}ä¸ªæ ·æœ¬ï¼Œ{X.shape[1]}ä¸ªç‰¹å¾")
    except KeyError as e:
        st.error(f"âŒ ç‰¹å¾åˆ—ä¸å­˜åœ¨ï¼š{str(e)}")
        if st.button("â† è¿”å›å˜é‡å®šä¹‰é¡µé¢", use_container_width=True):
            st.session_state.current_page = "å˜é‡å®šä¹‰ä¸ä»»åŠ¡è®¾ç½®"
            rerun()
        return

    # æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯
    with st.container():
        st.markdown(f"<div style='{st.session_state.card_style}'>", unsafe_allow_html=True)
        st.subheader("1. æ•°æ®é›†ä¿¡æ¯")

        col1, col2 = st.columns(2)
        with col1:
            st.write("**ä»»åŠ¡ç±»å‹**ï¼š", st.session_state.task_type)
            st.write("**ç›®æ ‡å˜é‡**ï¼š", st.session_state.target_col)
            st.write("**ç‰¹å¾æ•°é‡**ï¼š", len(st.session_state.features))

        with col2:
            st.write("**æ ·æœ¬æ•°é‡**ï¼š", X.shape[0])
            st.write("**ç‰¹å¾åˆ—è¡¨**ï¼š",
                     ", ".join(st.session_state.features[:5]) + ("..." if len(st.session_state.features) > 5 else ""))

        # æ•°æ®é›†æ‹†åˆ†é…ç½®
        st.subheader("2. æ•°æ®é›†æ‹†åˆ†")
        test_size = st.slider(
            "æµ‹è¯•é›†æ¯”ä¾‹",
            min_value=0.1,
            max_value=0.4,
            value=st.session_state.test_size,
            step=0.05,
            help="è®­ç»ƒé›†ä¸æµ‹è¯•é›†çš„åˆ’åˆ†æ¯”ä¾‹"
        )
        st.session_state.test_size = test_size

        # æ‰§è¡Œæ•°æ®é›†æ‹†åˆ†
        if st.button("ğŸ”„ æ‹†åˆ†è®­ç»ƒé›†ä¸æµ‹è¯•é›†", use_container_width=True):
            with st.spinner("æ­£åœ¨æ‹†åˆ†æ•°æ®é›†..."):
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y,
                    test_size=test_size,
                    random_state=st.session_state.random_state,
                    stratify=y if st.session_state.task_type == "åˆ†ç±»ä»»åŠ¡" else None
                )

                # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
                st.session_state.X_train = X_train
                st.session_state.X_test = X_test
                st.session_state.y_train = y_train
                st.session_state.y_test = y_test

                st.success(
                    f"âœ… æ•°æ®é›†æ‹†åˆ†å®Œæˆï¼š\n"
                    f"è®­ç»ƒé›†ï¼š{X_train.shape[0]}ä¸ªæ ·æœ¬ï¼Œ{X_train.shape[1]}ä¸ªç‰¹å¾\n"
                    f"æµ‹è¯•é›†ï¼š{X_test.shape[0]}ä¸ªæ ·æœ¬ï¼Œ{X_test.shape[1]}ä¸ªç‰¹å¾"
                )
        st.markdown("</div>", unsafe_allow_html=True)

    # æ¨¡å‹é€‰æ‹©ä¸è®­ç»ƒ
    if st.session_state.X_train is not None:
        with st.container():
            st.markdown(f"<div style='{st.session_state.card_style}'>", unsafe_allow_html=True)
            st.subheader("3. æ¨¡å‹é€‰æ‹©ä¸è®­ç»ƒ")

            # æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©æ¨¡å‹
            if st.session_state.task_type == "åˆ†ç±»ä»»åŠ¡":
                model_name = st.selectbox(
                    "é€‰æ‹©åˆ†ç±»æ¨¡å‹",
                    ["é€»è¾‘å›å½’", "å†³ç­–æ ‘", "éšæœºæ£®æ—", "æ¢¯åº¦æå‡æ ‘"]
                )

                # æ¨¡å‹å‚æ•°
                with st.expander("æ¨¡å‹å‚æ•°è®¾ç½®", expanded=False):
                    if model_name == "é€»è¾‘å›å½’":
                        C = st.slider("æ­£åˆ™åŒ–å¼ºåº¦ (C)", 0.01, 10.0, 1.0, 0.01)
                        max_iter = st.slider("æœ€å¤§è¿­ä»£æ¬¡æ•°", 100, 1000, 500, 100)
                        model = LogisticRegression(C=C, max_iter=max_iter, random_state=st.session_state.random_state)

                    elif model_name == "å†³ç­–æ ‘":
                        max_depth = st.slider("æ ‘æœ€å¤§æ·±åº¦", 3, 20, 5)
                        min_samples_split = st.slider("æœ€å°åˆ†è£‚æ ·æœ¬æ•°", 2, 20, 2)
                        model = DecisionTreeClassifier(
                            max_depth=max_depth,
                            min_samples_split=min_samples_split,
                            random_state=st.session_state.random_state
                        )

                    elif model_name == "éšæœºæ£®æ—":
                        n_estimators = st.slider("æ ‘çš„æ•°é‡", 50, 500, 100, 50)
                        max_depth = st.slider("æ ‘æœ€å¤§æ·±åº¦", 3, 20, 5)
                        model = RandomForestClassifier(
                            n_estimators=n_estimators,
                            max_depth=max_depth,
                            random_state=st.session_state.random_state
                        )

                    elif model_name == "æ¢¯åº¦æå‡æ ‘":
                        n_estimators = st.slider("æ ‘çš„æ•°é‡", 50, 500, 100, 50)
                        learning_rate = st.slider("å­¦ä¹ ç‡", 0.01, 0.3, 0.1, 0.01)
                        model = GradientBoostingClassifier(
                            n_estimators=n_estimators,
                            learning_rate=learning_rate,
                            random_state=st.session_state.random_state
                        )

            else:  # å›å½’ä»»åŠ¡
                model_name = st.selectbox(
                    "é€‰æ‹©å›å½’æ¨¡å‹",
                    ["çº¿æ€§å›å½’", "Ridgeå›å½’", "Lassoå›å½’", "å†³ç­–æ ‘", "éšæœºæ£®æ—", "æ¢¯åº¦æå‡æ ‘"]
                )

                # æ¨¡å‹å‚æ•°
                with st.expander("æ¨¡å‹å‚æ•°è®¾ç½®", expanded=False):
                    if model_name == "çº¿æ€§å›å½’":
                        model = LinearRegression()

                    elif model_name == "Ridgeå›å½’":
                        alpha = st.slider("æ­£åˆ™åŒ–å¼ºåº¦ (alpha)", 0.01, 10.0, 1.0, 0.01)
                        model = Ridge(alpha=alpha, random_state=st.session_state.random_state)

                    elif model_name == "Lassoå›å½’":
                        alpha = st.slider("æ­£åˆ™åŒ–å¼ºåº¦ (alpha)", 0.01, 10.0, 1.0, 0.01)
                        model = Lasso(alpha=alpha, random_state=st.session_state.random_state)

                    elif model_name == "å†³ç­–æ ‘":
                        max_depth = st.slider("æ ‘æœ€å¤§æ·±åº¦", 3, 20, 5)
                        min_samples_split = st.slider("æœ€å°åˆ†è£‚æ ·æœ¬æ•°", 2, 20, 2)
                        model = DecisionTreeRegressor(
                            max_depth=max_depth,
                            min_samples_split=min_samples_split,
                            random_state=st.session_state.random_state
                        )

                    elif model_name == "éšæœºæ£®æ—":
                        n_estimators = st.slider("æ ‘çš„æ•°é‡", 50, 500, 100, 50)
                        max_depth = st.slider("æ ‘æœ€å¤§æ·±åº¦", 3, 20, 5)
                        model = RandomForestRegressor(
                            n_estimators=n_estimators,
                            max_depth=max_depth,
                            random_state=st.session_state.random_state
                        )

                    elif model_name == "æ¢¯åº¦æå‡æ ‘":
                        n_estimators = st.slider("æ ‘çš„æ•°é‡", 50, 500, 100, 50)
                        learning_rate = st.slider("å­¦ä¹ ç‡", 0.01, 0.3, 0.1, 0.01)
                        model = GradientBoostingRegressor(
                            n_estimators=n_estimators,
                            learning_rate=learning_rate,
                            random_state=st.session_state.random_state
                        )

            # è®­ç»ƒæ¨¡å‹
            if st.button("ğŸš€ è®­ç»ƒæ¨¡å‹", use_container_width=True, type="primary"):
                with st.spinner(f"æ­£åœ¨è®­ç»ƒ{model_name}..."):
                    # ç‰¹å¾é¢„å¤„ç†
                    numeric_features = st.session_state.X_train.select_dtypes(include=[np.number]).columns.tolist()
                    categorical_features = st.session_state.X_train.select_dtypes(include=['object']).columns.tolist()

                    preprocessor = ColumnTransformer(
                        transformers=[
                            ('num', StandardScaler(), numeric_features),
                            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
                        ])

                    # åˆ›å»ºPipeline
                    pipeline = Pipeline(steps=[
                        ('preprocessor', preprocessor),
                        ('model', model)
                    ])

                    # è®­ç»ƒæ¨¡å‹
                    pipeline.fit(st.session_state.X_train, st.session_state.y_train)

                    # ä¿å­˜æ¨¡å‹
                    st.session_state.best_model = pipeline

                    # è¯„ä¼°æ¨¡å‹
                    y_pred = pipeline.predict(st.session_state.X_test)

                    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                    performance = {}
                    if st.session_state.task_type == "åˆ†ç±»ä»»åŠ¡":
                        performance["å‡†ç¡®ç‡"] = accuracy_score(st.session_state.y_test, y_pred)
                        performance["ç²¾ç¡®ç‡"] = precision_score(st.session_state.y_test, y_pred, average='weighted')
                        performance["å¬å›ç‡"] = recall_score(st.session_state.y_test, y_pred, average='weighted')
                        performance["F1åˆ†æ•°"] = f1_score(st.session_state.y_test, y_pred, average='weighted')

                        # å°è¯•è®¡ç®—AUCï¼ˆå¤šç±»åˆ«çš„æƒ…å†µä¸‹å¯èƒ½ä¸é€‚ç”¨ï¼‰
                        try:
                            if len(np.unique(st.session_state.y_test)) <= 2:  # äºŒåˆ†ç±»
                                y_pred_proba = pipeline.predict_proba(st.session_state.X_test)[:, 1]
                                performance["AUC"] = roc_auc_score(st.session_state.y_test, y_pred_proba)
                        except:
                            pass
                    else:  # å›å½’ä»»åŠ¡
                        performance["MSE"] = mean_squared_error(st.session_state.y_test, y_pred)
                        performance["RMSE"] = np.sqrt(performance["MSE"])
                        performance["MAE"] = mean_absolute_error(st.session_state.y_test, y_pred)
                        performance["RÂ²åˆ†æ•°"] = r2_score(st.session_state.y_test, y_pred)

                    st.session_state.model_performance = performance
                    st.success(f"âœ… {model_name}è®­ç»ƒå®Œæˆï¼")
            st.markdown("</div>", unsafe_allow_html=True)

    # æ¨¡å‹è¯„ä¼°ç»“æœ
    if st.session_state.best_model is not None and st.session_state.model_performance:
        with st.container():
            st.markdown(f"<div style='{st.session_state.card_style}'>", unsafe_allow_html=True)
            st.subheader("4. æ¨¡å‹è¯„ä¼°ç»“æœ")

            # æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
            col1, col2 = st.columns(2)
            metrics = list(st.session_state.model_performance.items())
            for i, (name, value) in enumerate(metrics):
                if i % 2 == 0:
                    with col1:
                        st.metric(name, f"{value:.4f}")
                else:
                    with col2:
                        st.metric(name, f"{value:.4f}")

            # å¯è§†åŒ–ç»“æœ
            st.subheader("5. ç»“æœå¯è§†åŒ–")
            if st.session_state.task_type == "åˆ†ç±»ä»»åŠ¡":
                # æ··æ·†çŸ©é˜µ
                y_pred = st.session_state.best_model.predict(st.session_state.X_test)
                cm = confusion_matrix(st.session_state.y_test, y_pred)

                plt.figure(figsize=(8, 6))
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                            xticklabels=np.unique(st.session_state.y_test),
                            yticklabels=np.unique(st.session_state.y_test))
                plt.xlabel('é¢„æµ‹æ ‡ç­¾')
                plt.ylabel('çœŸå®æ ‡ç­¾')
                plt.title('æ··æ·†çŸ©é˜µ')
                st.pyplot(plt)

                # åˆ†ç±»æŠ¥å‘Š
                with st.expander("æŸ¥çœ‹è¯¦ç»†åˆ†ç±»æŠ¥å‘Š", expanded=False):
                    report = classification_report(
                        st.session_state.y_test,
                        y_pred,
                        target_names=[str(c) for c in np.unique(st.session_state.y_test)]
                    )
                    st.text(report)
            else:
                # å›å½’ç»“æœå¯è§†åŒ–ï¼šé¢„æµ‹å€¼ vs çœŸå®å€¼
                y_pred = st.session_state.best_model.predict(st.session_state.X_test)

                plt.figure(figsize=(8, 6))
                plt.scatter(st.session_state.y_test, y_pred, alpha=0.6)
                plt.plot([st.session_state.y_test.min(), st.session_state.y_test.max()],
                         [st.session_state.y_test.min(), st.session_state.y_test.max()],
                         'r--')
                plt.xlabel('çœŸå®å€¼')
                plt.ylabel('é¢„æµ‹å€¼')
                plt.title('é¢„æµ‹å€¼ vs çœŸå®å€¼')
                st.pyplot(plt)

                # æ®‹å·®å›¾
                plt.figure(figsize=(8, 6))
                residuals = st.session_state.y_test - y_pred
                plt.scatter(y_pred, residuals, alpha=0.6)
                plt.axhline(y=0, color='r', linestyle='--')
                plt.xlabel('é¢„æµ‹å€¼')
                plt.ylabel('æ®‹å·®')
                plt.title('æ®‹å·®å›¾')
                st.pyplot(plt)
            st.markdown("</div>", unsafe_allow_html=True)

    # å¯¼èˆªæŒ‰é’®
    with st.container():
        page_flow = st.session_state.page_flow
        try:
            current_idx = page_flow.index(st.session_state.current_page)
        except ValueError:
            current_idx = 2  # æ¨¡å‹è®­ç»ƒé¡µé¢é»˜è®¤ç´¢å¼•

        col_prev, col_next = st.columns(2)
        with col_prev:
            if current_idx > 0:
                if st.button(f"â† ä¸Šä¸€æ­¥ï¼š{page_flow[current_idx - 1]}", use_container_width=True):
                    st.session_state.current_page = page_flow[current_idx - 1]
                    rerun()
